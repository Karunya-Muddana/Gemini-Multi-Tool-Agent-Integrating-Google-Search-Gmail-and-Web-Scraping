{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356884ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_gemini_api_key = \"Your key here\"\n",
    "google_search_api_key = \"Your key here\"\n",
    "google_search_engine_id = \"Your key here\"\n",
    "google_gmail_client_id = \"Your key here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os.path\n",
    "from email.message import EmailMessage\n",
    "\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "\n",
    "\n",
    "SCOPES = [\"https://www.googleapis.com/auth/gmail.compose\"]\n",
    "\n",
    "\n",
    "def create_gmail_draft_with_auth(To, From, Subject, Body):\n",
    "  \"\"\"\n",
    "  Handles user authentication and creates a new draft email.\n",
    "\n",
    "  Args:\n",
    "    To: Email address of the recipient.\n",
    "    From: Email address of the sender.\n",
    "    Subject: The subject of the email.\n",
    "    Body: The plain text content of the email.\n",
    "  \"\"\"\n",
    "  creds = None\n",
    "\n",
    "  if os.path.exists(\"token.json\"):\n",
    "    creds = Credentials.from_authorized_user_file(\"token.json\", SCOPES)\n",
    "\n",
    "  # If there are no (valid) credentials available, let the user log in.\n",
    "  if not creds or not creds.valid:\n",
    "    if creds and creds.expired and creds.refresh_token:\n",
    "      creds.refresh(Request())\n",
    "    else:\n",
    "      # You must have a 'client_secrets.json' file in this directory\n",
    "      if not os.path.exists(\"client_secrets.json\"):\n",
    "        print(\"\\n--- ERROR ---\")\n",
    "        print(\"Missing 'client_secrets.json'.\")\n",
    "        print(\n",
    "            \"Please download it from your Google Cloud Console and place it in this directory.\"\n",
    "        )\n",
    "        print(\"---------------\\n\")\n",
    "        return None\n",
    "\n",
    "      flow = InstalledAppFlow.from_client_secrets_file(\n",
    "          \"client_secrets.json\", SCOPES\n",
    "      )\n",
    "      creds = flow.run_local_server(port=0)\n",
    "\n",
    "    # Save the credentials for the next run\n",
    "    with open(\"token.json\", \"w\") as token:\n",
    "      token.write(creds.to_json())\n",
    "\n",
    "  if creds:\n",
    "    try:\n",
    "      # create gmail api client\n",
    "      service = build(\"gmail\", \"v1\", credentials=creds)\n",
    "\n",
    "      message = EmailMessage()\n",
    "      message.set_content(Body)\n",
    "      message[\"To\"] = To\n",
    "      message[\"From\"] = From\n",
    "      message[\"Subject\"] = Subject\n",
    "\n",
    "      # encoded message\n",
    "      encoded_message = base64.urlsafe_b64encode(message.as_bytes()).decode()\n",
    "\n",
    "      create_message = {\"message\": {\"raw\": encoded_message}}\n",
    "\n",
    "      # pylint: disable=E1101\n",
    "      draft = (\n",
    "          service.users()\n",
    "          .drafts()\n",
    "          .create(userId=\"me\", body=create_message)\n",
    "          .execute()\n",
    "      )\n",
    "\n",
    "      print(f'Draft id: {draft[\"id\"]}\\nDraft message: {draft[\"message\"]}')\n",
    "      return draft\n",
    "\n",
    "    except HttpError as error:\n",
    "      print(f\"An error occurred: {error}\")\n",
    "      return None\n",
    "  \n",
    "  print(\"Could not obtain credentials.\")\n",
    "  return None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4113348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def google_search(query, api_key, cse_id, num_results=5):\n",
    "    search_url = \"https://www.googleapis.com/customsearch/v1\"\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'key': api_key,\n",
    "        'cx': cse_id,\n",
    "    }\n",
    "    response = requests.get(search_url, params=params)\n",
    "    results = response.json().get('items', [])[:num_results]\n",
    "\n",
    "    out = []\n",
    "    for item in results:\n",
    "        title = item.get(\"title\")\n",
    "        snippet = item.get(\"snippet\")\n",
    "        link = item.get(\"link\")\n",
    "        out.append({\"title\": title, \"content\": snippet, \"link\": link})\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7dc1bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "def wiki_search(query, num_results=5):\n",
    "    search_results = wikipedia.search(query, results=num_results)\n",
    "    out = []\n",
    "    for title in search_results:\n",
    "        try:\n",
    "            page = wikipedia.page(title)\n",
    "            summary = wikipedia.summary(title, sentences=2)\n",
    "            out.append({\"title\": title, \"content\": summary, \"link\": page.url})\n",
    "        except wikipedia.DisambiguationError as e:\n",
    "            continue\n",
    "        except wikipedia.PageError as e:\n",
    "            continue\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f41eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import trafilatura\n",
    "# from bs4 import BeautifulSoup # You can remove this import if you want\n",
    "\n",
    "def fetch_page_content(url):\n",
    "    \"\"\"\n",
    "    Fetch and extract main article content using trafilatura,\n",
    "    which is more robust against anti-scraping.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Extract the main content from the HTML\n",
    "\n",
    "        page_text = trafilatura.extract(response.text, include_comments=False, include_tables=False)\n",
    "        \n",
    "        if not page_text:\n",
    "            return {\"error\": \"Could not extract main content from the page.\"}\n",
    "        \n",
    "        return page_text[:4000] # Return content string on success\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        # Return an error dictionary on failure\n",
    "        return {\"error\": f\"Could not fetch page content. Error: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c5cfd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools list defined.\n"
     ]
    }
   ],
   "source": [
    "# --- Tool Definitions Cell ---\n",
    "\n",
    "from google.genai import types\n",
    "\n",
    "tools = [\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(\n",
    "                name=\"google_search\",\n",
    "                description=\"Search Google using the Custom Search API\",\n",
    "                parameters=types.Schema(\n",
    "                    type=\"object\",\n",
    "                    properties={\n",
    "                        \"query\": {\"type\": \"string\"},\n",
    "                        \"num_results\": {\"type\": \"integer\"},\n",
    "                    },\n",
    "                    required=[\"query\"]\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(\n",
    "                name=\"fetch_page_content\",\n",
    "                description=\"Fetch and clean readable text from a given webpage URL\",\n",
    "                parameters=types.Schema(\n",
    "                    type=\"object\",\n",
    "                    properties={\n",
    "                        \"url\": {\"type\": \"string\"},\n",
    "                    },\n",
    "                    required=[\"url\"]\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(\n",
    "                name=\"wiki_search\",\n",
    "                description=\"Search Wikipedia for relevant articles\",\n",
    "                parameters=types.Schema(\n",
    "                    type=\"object\",\n",
    "                    properties={\n",
    "                        \"query\": {\"type\": \"string\"},\n",
    "                        \"num_results\": {\"type\": \"integer\"},\n",
    "                    },\n",
    "                    required=[\"query\"]\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    types.Tool(\n",
    "        function_declarations=[\n",
    "            types.FunctionDeclaration(\n",
    "                name=\"create_gmail_draft_with_auth\",\n",
    "                description=\"Create a Gmail draft email using authenticated user credentials\",\n",
    "                parameters=types.Schema(\n",
    "                    type=\"object\",\n",
    "                    properties={\n",
    "                        \"To\": {\"type\": \"string\"},\n",
    "                        \"From\": {\"type\": \"string\"},\n",
    "                        \"Subject\": {\"type\": \"string\"},\n",
    "                        \"Body\": {\"type\": \"string\"},\n",
    "                    },\n",
    "                    required=[\"To\", \"From\", \"Subject\", \"Body\"]\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"Tools list defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72098b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing conversation. History loaded with 2 setup messages. ---\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DEBUG: Appending USER turn.\n",
      "DEBUG: Calling generate_content (Cycle Start)...\n",
      "DEBUG: Model response IS a function call.\n",
      "\n",
      "--- Model requested 1 tool call(s) ---\n",
      "Executing: google_search({'query': 'RTX 5070'})\n",
      "DEBUG: Appending TOOL turn.\n",
      "\n",
      "--- Added 1 tool results. Re-prompting model... ---\n",
      "DEBUG: Calling generate_content (after tool)...\n",
      "DEBUG: Appending final MODEL turn (after tool).\n",
      "\n",
      "--- MODEL RESPONSE ---\n",
      "The NVIDIA GeForce RTX 5070 is a high-end graphics card that is part of NVIDIA's 50-series, based on the Blackwell architecture. It is built on a 5 nm process and utilizes the GB205 graphics processor. The card is expected to be launched around March or April 2025 and features 12GB of GDDR7 VRAM. There is also a mention of an RTX 5070 Ti.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DEBUG: Appending USER turn.\n",
      "DEBUG: Calling generate_content (Cycle Start)...\n",
      "DEBUG: Model response IS a function call.\n",
      "\n",
      "--- Model requested 1 tool call(s) ---\n",
      "Executing: create_gmail_draft_with_auth({'To': 'kushi.muddana@gmail.com', 'Subject': 'Information on RTX 5070', 'From': 'me', 'Body': \"The NVIDIA GeForce RTX 5070 is a high-end graphics card that is part of NVIDIA's 50-series, based on the Blackwell architecture. It is built on a 5 nm process and utilizes the GB205 graphics processor. The card is expected to be launched around March or April 2025 and features 12GB of GDDR7 VRAM. There is also a mention of an RTX 5070 Ti.\"})\n",
      "Draft id: r-6351792973655748699\n",
      "Draft message: {'id': '19a19d28c947c99a', 'threadId': '19a19d28c947c99a', 'labelIds': ['DRAFT']}\n",
      "DEBUG: Appending TOOL turn.\n",
      "\n",
      "--- Added 1 tool results. Re-prompting model... ---\n",
      "DEBUG: Calling generate_content (after tool)...\n",
      "DEBUG: Appending final MODEL turn (after tool).\n",
      "\n",
      "--- MODEL RESPONSE ---\n",
      "I have successfully created a draft email with the information about the RTX 5070 and sent it to kushi.muddana@gmail.com.\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "DEBUG: Appending USER turn.\n",
      "DEBUG: Calling generate_content (Cycle Start)...\n",
      "DEBUG: Model response is TEXT.\n",
      "\n",
      "--- MODEL RESPONSE ---\n",
      "You're welcome! Is there anything else I can assist you with today?\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Exiting conversation.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import pprint\n",
    "\n",
    "# -----------------------------\n",
    "# Gemini Client and Tool Setup\n",
    "# (Assumes your 'tools' list is defined in a cell above)\n",
    "# -----------------------------\n",
    "\n",
    "client = genai.Client(api_key=google_gemini_api_key)\n",
    "config = types.GenerateContentConfig(tools=tools)\n",
    "\n",
    "\n",
    "conversation_history = [\n",
    "    types.Content(role=\"user\", parts=[\n",
    "        types.Part(text=\"\"\"You are a reliable assistant that can use external tools to retrieve accurate,\n",
    "    up-to-date information from the web. Always start with `Google Search` to find\n",
    "    relevant sources, then use `fetch_page_content` if needed, and summarize the results.\"\"\")\n",
    "    ]),\n",
    "    types.Content(role=\"model\", parts=[\n",
    "        types.Part(text=\"Okay, I'm ready to help. What would you like to know?\")\n",
    "    ])\n",
    "]\n",
    "print(\"--- Initializing conversation. History loaded with 2 setup messages. ---\")\n",
    "\n",
    "\n",
    "def print_debug_history(history, max_turns=10):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"DEBUG: PRINTING LAST {min(len(history), max_turns)} HISTORY TURNS (Max: {max_turns})\")\n",
    "    print(\"=\"*50)\n",
    "    start_index = max(0, len(history) - max_turns)\n",
    "    debug_history = history[start_index:]\n",
    "    for i, content in enumerate(debug_history, start=start_index):\n",
    "        role = content.role\n",
    "        print(f\"\\n--- Turn {i} ({role}) ---\")\n",
    "        try:\n",
    "            if role == \"model\" and hasattr(content.parts[0], 'function_call') and content.parts[0].function_call.name:\n",
    "                fc = content.parts[0].function_call\n",
    "                print(f\"Function Call: {fc.name}\")\n",
    "                print(f\"Args:\\n{pprint.pformat(dict(fc.args))}\")\n",
    "            elif role == \"tool\" and hasattr(content.parts[0], 'function_response') and content.parts[0].function_response.name:\n",
    "                 fr = content.parts[0].function_response\n",
    "                 print(f\"Function Response: {fr.name}\")\n",
    "                 response_dict = getattr(fr, 'response', {})\n",
    "                 if isinstance(response_dict, dict):\n",
    "                      print(f\"Data:\\n{pprint.pformat(dict(response_dict))}\")\n",
    "                 else:\n",
    "                      print(f\"Data (raw): {response_dict}\")\n",
    "            else:\n",
    "                 combined_text = \"\".join(part.text for part in content.parts if hasattr(part, 'text'))\n",
    "                 print(combined_text)\n",
    "        except Exception as e:\n",
    "            print(f\"[Debug print error: {e}] - Raw parts: {content.parts}\")\n",
    "    print(\"\\n\" + \"=\"*50 + \" END OF HISTORY PRINT \" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Main Interaction Loop ---\n",
    "while True:\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    if conversation_history and conversation_history[-1].role != \"model\":\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        print(f\"DEBUG ERROR: Expected last turn to be 'model', but got '{conversation_history[-1].role}'.\")\n",
    "        print(\"Attempting to recover by adding placeholder model response.\")\n",
    "        print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "        conversation_history.append(types.Content(role=\"model\", parts=[types.Part(text=\"[Error recovery placeholder]\")]))\n",
    "        # Optionally break or raise an error here if recovery is not desired\n",
    "\n",
    "    user_prompt = input(\"USER: \")\n",
    "    print(user_prompt)\n",
    "    if user_prompt.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"Exiting conversation.\")\n",
    "        break\n",
    "\n",
    "    print(f\"DEBUG: Appending USER turn.\")\n",
    "    conversation_history.append(\n",
    "        types.Content(role=\"user\", parts=[types.Part(text=user_prompt)])\n",
    "    )\n",
    "\n",
    "    # --- Start Interaction ---\n",
    "    try:\n",
    "        #print_debug_history(conversation_history, max_turns=10)\n",
    "        print(\"DEBUG: Calling generate_content (Cycle Start)...\")\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=conversation_history[-10:], # Send recent history\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        if not response.candidates:\n",
    "            raise ValueError(\"Model returned no candidates.\") # Treat as an error\n",
    "\n",
    "        model_response_content = response.candidates[0].content\n",
    "\n",
    "        # --- Process Potential Function Calls ---\n",
    "        if response.function_calls:\n",
    "            print(\"DEBUG: Model response IS a function call.\")\n",
    "            conversation_history.append(model_response_content) # Append the function call request\n",
    "\n",
    "            calls = response.function_calls\n",
    "            print(f\"\\n--- Model requested {len(calls)} tool call(s) ---\")\n",
    "            tool_results_parts = []\n",
    "            all_calls_valid = True # Flag to track if we should proceed\n",
    "\n",
    "            for call in calls:\n",
    "                func_name = call.name\n",
    "                args = dict(call.args)\n",
    "                print(f\"Executing: {func_name}({args})\")\n",
    "                response_data = {}\n",
    "                missing_arg = False\n",
    "\n",
    "                # Argument Validation\n",
    "                required_args = []\n",
    "                if func_name == \"google_search\": required_args = [\"query\"]\n",
    "                elif func_name == \"fetch_page_content\": required_args = [\"url\"]\n",
    "                elif func_name == \"wiki_search\": required_args = [\"query\"]\n",
    "                elif func_name == \"create_gmail_draft_with_auth\": required_args = [\"To\", \"From\", \"Subject\", \"Body\"]\n",
    "\n",
    "                for req_arg in required_args:\n",
    "                    if req_arg not in args or not args[req_arg]:\n",
    "                        print(f\"ERROR: Missing required argument '{req_arg}' for tool '{func_name}'.\")\n",
    "                        response_data = {\"content\": {\"error\": f\"Missing required argument: {req_arg}\"}}\n",
    "                        missing_arg = True\n",
    "                        all_calls_valid = False # Mark that at least one call failed validation\n",
    "                        break\n",
    "\n",
    "                if missing_arg:\n",
    "                    # Append error for this specific call\n",
    "                    tool_results_parts.append(types.Part(function_response=types.FunctionResponse(name=func_name, response=response_data)))\n",
    "                    # Continue processing other calls if any, but we won't make the final model call if any failed\n",
    "                    continue # Go to the next function call\n",
    "\n",
    "                # Execute Tool if Arguments are Valid\n",
    "                try:\n",
    "                    if func_name == \"google_search\":\n",
    "                        results = google_search(query=args[\"query\"], api_key=google_search_api_key, cse_id=google_search_engine_id, num_results=args.get(\"num_results\", 5))\n",
    "                        response_data = {\"content\": results}\n",
    "                    elif func_name == \"fetch_page_content\":\n",
    "                        content = fetch_page_content(url=args[\"url\"])\n",
    "                        response_data = {\"content\": content}\n",
    "                    elif func_name == \"wiki_search\":\n",
    "                         results = wiki_search(query=args[\"query\"], num_results=args.get(\"num_results\", 3))\n",
    "                         response_data = {\"content\": results}\n",
    "                    elif func_name == \"create_gmail_draft_with_auth\":\n",
    "                          draft = create_gmail_draft_with_auth(To=args[\"To\"], From=args[\"From\"], Subject=args[\"Subject\"], Body=args[\"Body\"])\n",
    "                          response_data = {\"content\": f\"Draft created successfully: {draft}\"}\n",
    "                    else:\n",
    "                        print(f\"Unknown function call: {func_name}\")\n",
    "                        response_data = {\"content\": {\"error\": f\"Unknown tool {func_name}\"}}\n",
    "                except Exception as e:\n",
    "                     print(f\"ERROR executing tool {func_name}: {e}\")\n",
    "                     response_data = {\"content\": {\"error\": f\"Error during tool execution: {e}\"}}\n",
    "                     all_calls_valid = False # Mark failure\n",
    "\n",
    "                tool_results_parts.append(\n",
    "                    types.Part(function_response=types.FunctionResponse(\n",
    "                        name=func_name,\n",
    "                        response=response_data\n",
    "                    ))\n",
    "                )\n",
    "            # --- End For Loop (Processing Calls) ---\n",
    "\n",
    "            print(f\"DEBUG: Appending TOOL turn.\")\n",
    "            conversation_history.append(\n",
    "                types.Content(role=\"tool\", parts=tool_results_parts)\n",
    "            )\n",
    "\n",
    "            if not all_calls_valid:\n",
    "                 print(\"DEBUG: One or more tool calls failed validation or execution. Skipping final model call for this turn.\")\n",
    "                 # Add a placeholder model response indicating the tool failure\n",
    "                 model_response_content = types.Content(role=\"model\", parts=[types.Part(text=\"I encountered an error trying to use my tools. Please check the arguments or try again.\")])\n",
    "                 conversation_history.append(model_response_content)\n",
    "                 # Go directly to final print for this turn\n",
    "\n",
    "            else:\n",
    "                 print(f\"\\n--- Added {len(tool_results_parts)} tool results. Re-prompting model... ---\")\n",
    "                 #print_debug_history(conversation_history, max_turns=10)\n",
    "                 print(\"DEBUG: Calling generate_content (after tool)...\")\n",
    "                 response = client.models.generate_content(\n",
    "                     model=\"gemini-2.5-flash\",\n",
    "                     contents=conversation_history[-10:],\n",
    "                     config=config,\n",
    "                 )\n",
    "\n",
    "                 if not response.candidates:\n",
    "                     raise ValueError(\"Model returned no candidates after tool call.\")\n",
    "\n",
    "                 model_response_content = response.candidates[0].content\n",
    "\n",
    "                 # Check if the response *after* the tool call is ANOTHER function call\n",
    "                 if response.function_calls:\n",
    "                      print(\"DEBUG WARNING: Model requested another function call immediately after a tool response. This might loop, appending placeholder.\")\n",
    "                      # Append a placeholder to avoid potential infinite loops and history corruption\n",
    "                      model_response_content = types.Content(role=\"model\", parts=[types.Part(text=\"[Unexpected function call loop detected]\")])\n",
    "\n",
    "                 # Append the final text response (or the warning placeholder)\n",
    "                 print(\"DEBUG: Appending final MODEL turn (after tool).\")\n",
    "                 conversation_history.append(model_response_content)\n",
    "\n",
    "        # --- End If Function Call Block ---\n",
    "        else:\n",
    "             # --- It was a Text Response ---\n",
    "             print(\"DEBUG: Model response is TEXT.\")\n",
    "             conversation_history.append(model_response_content) # Append the text response\n",
    "             # No further action needed, proceed to final print\n",
    "\n",
    "    # --- Error Handling for the whole interaction block ---\n",
    "    except Exception as e:\n",
    "        print(f\"\\n--- CRITICAL ERROR during model interaction: {e} ---\")\n",
    "        # Ensure a model response is added, even if it's an error\n",
    "        model_response_content = types.Content(role=\"model\", parts=[types.Part(text=f\"[Critical error during processing: {e}]\")])\n",
    "        # Only append if the last turn wasn't already this error\n",
    "        if not conversation_history or conversation_history[-1] is not model_response_content:\n",
    "             conversation_history.append(model_response_content)\n",
    "\n",
    "    # --- Output Final Response ---\n",
    "    final_model_content = conversation_history[-1] # Should always be the last model response\n",
    "    final_text = \"\"\n",
    "\n",
    "    if final_model_content.role == \"model\":\n",
    "        for part in final_model_content.parts:\n",
    "             if hasattr(part, 'text'):\n",
    "                  final_text += part.text\n",
    "    else:\n",
    "        print(f\"DEBUG: ERROR - Last history item was '{final_model_content.role}', expected 'model'!\")\n",
    "        final_text = \"[Error in history processing - check logs]\"\n",
    "\n",
    "\n",
    "    print(\"\\n--- MODEL RESPONSE ---\")\n",
    "    if final_text:\n",
    "        print(final_text)\n",
    "    else:\n",
    "         # Check if it ended because of a function call that wasn't expected\n",
    "         try:\n",
    "              if final_model_content.parts[0].function_call.name:\n",
    "                   print(\"[Error: Loop ended unexpectedly on a function call - check logs]\")\n",
    "         except: # No function call, expected case if text is empty\n",
    "              print(\"[Model had no text response or an error occurred - check logs]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
